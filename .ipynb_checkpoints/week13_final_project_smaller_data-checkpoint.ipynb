{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import epitran\n",
    "os.chdir(\"/Users/Clair/machine_learning_sp20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"ara-Arab\", \"aze-Latn\", \"ben-Beng\", \"cat-Latn\", \"deu-Latn\", \"spa-Latn\", \"fra-Latn\", \"hun-Latn\", \n",
    "         \"ind-Latn\", \"ita-Latn\", \"mar-Deva\", \"msa-Latn\", \"mlt-Latn\", \"nld-Latn\", \"pol-Latn\", \"por-Latn\", \n",
    "        \"ron-Latn\", \"rus-Cyrl\", \"swe-Latn\", \"swa-Latn\", \"tam-Taml\", \"tel-Telu\", \"tha-Thai\", \"tuk-Latn\",\n",
    "       \"tgl-Latn\", \"tur-Latn\", \"ukr-Cyrl\", \"uzb-Latn\", \"vie-Latn\"]\n",
    "abbrevs = [\"ar\", \"az\", \"bn\", \"ca\", \"de\", \"es\", \"fr\", \"hu\", \"id\", \"it\", \"mr\", \"ms\", \"mt\", \"nl\", \n",
    "           \"pl\", \"pt\", \"ro\", \"ru\", \"sl\",\"sw\", \"ta\", \"te\", \"th\", \"tk\", \"tl\", \"tr\", \"uk\", \"uz\", \"vi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnknownChars(words):\n",
    "    for word in words:\n",
    "        word = filter(lambda x: x in string.printable, word)\n",
    "    return words\n",
    "            \n",
    "def readInFile(rel_path):\n",
    "    text_file = open(rel_path, \"r\", encoding=\"utf-8\")\n",
    "    words = text_file.read().split('\\n')\n",
    "    return words\n",
    "\n",
    "def translit(words, lang):\n",
    "    epi = epitran.Epitran(lang)\n",
    "    ipa = []\n",
    "    for word in words:\n",
    "        ipa.append(epi.transliterate(word))\n",
    "    return ipa\n",
    "\n",
    "def buildNPath(abbrev):\n",
    "    return \"C:/Users/Clair/machine_learning_sp20/Final_Project/sentiment_lexicons/negative_words_\" + abbrev + \".txt\"\n",
    "\n",
    "def buildPPath(abbrev):\n",
    "    return \"C:/Users/Clair/machine_learning_sp20/Final_Project/sentiment_lexicons/positive_words_\" + abbrev + \".txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang = ar completed\n",
      "Lang = az completed\n",
      "Lang = bn completed\n",
      "Lang = ca completed\n",
      "Lang = de completed\n",
      "Lang = es completed\n",
      "Lang = fr completed\n",
      "Lang = hu completed\n",
      "Lang = id completed\n",
      "Lang = it completed\n",
      "Lang = mr completed\n",
      "Lang = ms completed\n",
      "Lang = mt completed\n",
      "Lang = nl completed\n",
      "Lang = pl completed\n",
      "Lang = pt completed\n",
      "Lang = ro completed\n",
      "Lang = ru completed\n",
      "Lang = sl completed\n",
      "Lang = sw completed\n",
      "Lang = ta completed\n",
      "Lang = te completed\n",
      "Lang = th completed\n",
      "Lang = tk completed\n",
      "Lang = tl completed\n",
      "Lang = tr completed\n",
      "Lang = uk completed\n",
      "Lang = uz completed\n",
      "Lang = vi completed\n"
     ]
    }
   ],
   "source": [
    "n_ipas = []\n",
    "p_ipas = []\n",
    "\n",
    "length = 0;\n",
    "i = 0\n",
    "for lang in langs:\n",
    "\n",
    "    n_words = removeUnknownChars(readInFile(buildNPath(abbrevs[i])))\n",
    "    p_words = removeUnknownChars(readInFile(buildPPath(abbrevs[i])))\n",
    "\n",
    "    n_ipa = translit(n_words, lang)\n",
    "    p_ipa = translit(p_words, lang)\n",
    "    \n",
    "    ln = len(max(n_ipa, key=len))\n",
    "    lp = len(max(p_ipa, key=len))\n",
    "    \n",
    "    if (ln > length):\n",
    "        length = ln\n",
    "    if (lp > length):\n",
    "        length = lp\n",
    "    \n",
    "    n_ipas.extend(n_ipa)\n",
    "    p_ipas.extend(p_ipa)\n",
    "    print(\"Lang =\", abbrevs[i], \"completed\")\n",
    "\n",
    "    i += 1;\n",
    "\n",
    "    \n",
    "#n_ipas.append(translit(buildNPath(\"zh\"), \"cmn-Hans\"))\n",
    "#p_ipas.append(translit(buildPPath(\"zh\"), \"cmn-Hans\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(n_ipas)\n",
    "random.shuffle(p_ipas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = []\n",
    "p_list = []\n",
    "\n",
    "transaction = []\n",
    "\n",
    "wordId = 0\n",
    "\n",
    "for i in range(len(n_ipas)):\n",
    "    word = n_ipas[i]\n",
    "    word_list = [wordId]\n",
    "    for letter in word:\n",
    "        word_list.append(letter)\n",
    "    n_list.append(word_list)\n",
    "    wordId += 1\n",
    "\n",
    "wordId = 0\n",
    "for i in range(len(p_ipas)):\n",
    "    word = p_ipas[i]\n",
    "    word_list = [wordId]\n",
    "    for letter in word:\n",
    "        word_list.append(letter)\n",
    "    p_list.append(word_list)\n",
    "    wordId += 1    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(n_list)\n",
    "my_df.to_csv('neg_list.csv', encoding=\"utf-8\", index=False, headers=False)\n",
    "\n",
    "my_df = pd.DataFrame(p_list)\n",
    "my_df.to_csv('pos_list.csv', encoding=\"utf-8\", index=False, headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
