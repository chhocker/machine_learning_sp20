{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/Clair/machine_learning_sp20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# DATASET #1\n",
    "# Breast Cancer Tumor Analysis\n",
    "# -Classification\n",
    "#################################################################\n",
    "cancer_columns = [\"id_num\", \"diagnosis\", \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \n",
    "                  \"compactness1\", \"concavity1\", \"concave_pts1\", \"symmetry1\", \"fract_dimen1\",\n",
    "                 \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \n",
    "                  \"compactness2\", \"concavity2\", \"concave_pts2\", \"symmetry2\", \"fract_dimen2\",\n",
    "                 \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \n",
    "                  \"compactness3\", \"concavity3\", \"concave_pts3\", \"symmetry3\", \"fract_dimen3\"]\n",
    "cancer_data = pd.read_csv(\"wdbc.data\", delimiter=\",\", names=cancer_columns, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data[\"is_malig\"] = cancer_data.diagnosis.map({\"M\": 1, \"B\": 0})\n",
    "\n",
    "cancer_targets = cancer_data[\"is_malig\"]\n",
    "cancer_data = cancer_data.drop(columns=[\"id_num\", \"diagnosis\", \"is_malig\"])\n",
    "\n",
    "cancer_data = cancer_data[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(cancer_data, cancer_targets,\n",
    "                                                                      stratify = cancer_targets,\n",
    "                                                                      test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer with 5 inputs neurons\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=30, units=3, kernel_initializer=\"uniform\"))\n",
    "\n",
    "#Hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "classifier.add(Dense(activation=\"relu\", units=3, kernel_initializer=\"uniform\"))\n",
    "\n",
    "\n",
    "#output layer with 1 output neuron which will predict 1 or 0\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/20\n",
      "398/398 [==============================] - 0s 475us/step - loss: 0.6925 - accuracy: 0.6055 - val_loss: 0.6914 - val_accuracy: 0.6257\n",
      "Epoch 2/20\n",
      "398/398 [==============================] - 0s 63us/step - loss: 0.6904 - accuracy: 0.6357 - val_loss: 0.6890 - val_accuracy: 0.6550\n",
      "Epoch 3/20\n",
      "398/398 [==============================] - 0s 70us/step - loss: 0.6876 - accuracy: 0.7487 - val_loss: 0.6850 - val_accuracy: 0.8655\n",
      "Epoch 4/20\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.6825 - accuracy: 0.8894 - val_loss: 0.6785 - val_accuracy: 0.7895\n",
      "Epoch 5/20\n",
      "398/398 [==============================] - 0s 73us/step - loss: 0.6740 - accuracy: 0.6005 - val_loss: 0.6676 - val_accuracy: 0.4444\n",
      "Epoch 6/20\n",
      "398/398 [==============================] - 0s 70us/step - loss: 0.6647 - accuracy: 0.4095 - val_loss: 0.6579 - val_accuracy: 0.4152\n",
      "Epoch 7/20\n",
      "398/398 [==============================] - 0s 80us/step - loss: 0.6548 - accuracy: 0.4070 - val_loss: 0.6492 - val_accuracy: 0.4386\n",
      "Epoch 8/20\n",
      "398/398 [==============================] - 0s 78us/step - loss: 0.6452 - accuracy: 0.4548 - val_loss: 0.6390 - val_accuracy: 0.4561\n",
      "Epoch 9/20\n",
      "398/398 [==============================] - 0s 83us/step - loss: 0.6344 - accuracy: 0.4874 - val_loss: 0.6266 - val_accuracy: 0.5263\n",
      "Epoch 10/20\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.6198 - accuracy: 0.6106 - val_loss: 0.6111 - val_accuracy: 0.6784\n",
      "Epoch 11/20\n",
      "398/398 [==============================] - 0s 75us/step - loss: 0.6018 - accuracy: 0.7487 - val_loss: 0.5915 - val_accuracy: 0.8713\n",
      "Epoch 12/20\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.5790 - accuracy: 0.8593 - val_loss: 0.5662 - val_accuracy: 0.8772\n",
      "Epoch 13/20\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.5534 - accuracy: 0.8492 - val_loss: 0.5402 - val_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "398/398 [==============================] - 0s 85us/step - loss: 0.5274 - accuracy: 0.8794 - val_loss: 0.5147 - val_accuracy: 0.9006\n",
      "Epoch 15/20\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.5045 - accuracy: 0.8719 - val_loss: 0.4929 - val_accuracy: 0.9298\n",
      "Epoch 16/20\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.4857 - accuracy: 0.8945 - val_loss: 0.4749 - val_accuracy: 0.9240\n",
      "Epoch 17/20\n",
      "398/398 [==============================] - 0s 75us/step - loss: 0.4700 - accuracy: 0.8995 - val_loss: 0.4581 - val_accuracy: 0.9240\n",
      "Epoch 18/20\n",
      "398/398 [==============================] - 0s 103us/step - loss: 0.4557 - accuracy: 0.8920 - val_loss: 0.4473 - val_accuracy: 0.9181\n",
      "Epoch 19/20\n",
      "398/398 [==============================] - 0s 90us/step - loss: 0.4442 - accuracy: 0.9020 - val_loss: 0.4375 - val_accuracy: 0.9240\n",
      "Epoch 20/20\n",
      "398/398 [==============================] - 0s 128us/step - loss: 0.4335 - accuracy: 0.9121 - val_loss: 0.4223 - val_accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ep = 20\n",
    "history = classifier.fit(train_data, train_targets,\n",
    "                    epochs=ep,\n",
    "                    validation_data=(test_data, test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 20\n",
      "Test loss: 0.422, Test Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = classifier.evaluate(test_data, test_targets, verbose=0)\n",
    "print(\"Number of epochs:\", ep)\n",
    "print('Test loss: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  95.91 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(train_data, train_targets);\n",
    "print(\"Accuracy: \", round(gbc.score(test_data, test_targets) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  94.74 %\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_data, train_targets);\n",
    "\n",
    "print(\"Accuracy: \", round(rf.score(test_data, test_targets) * 100, 2), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567425525700935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
